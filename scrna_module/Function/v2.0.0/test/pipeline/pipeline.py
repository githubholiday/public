
'''
Parameters:
	-i , --input : è¾“å…¥çš„é¡¹ç›®é…ç½®æ–‡ä»¶
	-b , --bin : ç¨‹åºè°ƒç”¨çš„ç›¸å…³ç¨‹åºè·¯å¾„ï¼Œä¸Žæµç¨‹é…ç½®æ–‡ä»¶ä¸­çš„${BIN}å¯¹åº”
	-t , --thread: çº¿ç¨‹æ•°ï¼Œå¦‚æžœå®šä¹‰äº†è¿™ä¸ªï¼Œé‚£ä¹ˆä¼šè¦†ç›–æµç¨‹é…ç½®æ–‡ä»¶ä¸­çš„CPU
	-q , --queue : æŒ‡å®šçš„é˜Ÿåˆ—ï¼Œå¦‚æžœå®šä¹‰äº†è¿™ä¸ªï¼Œåˆ™ä¼šè¦†ç›–æµç¨‹é…ç½®æ–‡ä»¶ä¸­çš„é˜Ÿåˆ—
	-P , --P : æŒ‡å®šçš„qsubçš„Projecté˜Ÿåˆ—ï¼Œé»˜è®¤æ˜¯noneï¼Œå³ä¸ºæ™®é€šé¡¹ç›®ï¼Œå¦‚æžœéœ€è¦åŠ æ€¥ï¼Œå¯ä»¥è®¾ç½®ä¸ºvipï¼ˆå…¨å°å†™ï¼‰
	-o , --outdir: è¾“å‡ºç›®å½•ï¼Œä¸Žæµç¨‹é…ç½®æ–‡ä»¶ä¸­çš„$(OUTDIR)å¯¹åº”
	-name,--name : ä»»åŠ¡åç§°
	-j,   --jobid: ä»»åŠ¡å‰ç¼€ï¼Œé»˜è®¤ä¸ºname
	-r,   --run  : æ˜¯å¦è‡ªåŠ¨æŠ•é€’ä»»åŠ¡ï¼Œé»˜è®¤ä¸ºä¸æŠ•é€’ä»»åŠ¡ï¼Œä½†ä¼šåœ¨${OUTDIR}/shellä¸­ç”Ÿæˆè„šæœ¬ï¼Œå¯ä»¥è¿›è¡Œæ£€æŸ¥
	-c,   --continue: åœ¨qsubä¸‹æœ‰æ•ˆï¼ˆè®¾ç½®äº†-rï¼Œä½†ä¸è®¾ç½®-nï¼‰ï¼Œå¦‚æžœæŸä¸€æ­¥åˆ†æžä¸­æ²¡æœ‰å®Œæˆå…¨éƒ¨ä»»åŠ¡ï¼Œå¦‚æžœä¸æŒ‡å®šåˆ™ä»Žå¤´è¿è¡Œè¯¥æ­¥æ‰€æœ‰ä»»åŠ¡ï¼ŒæŒ‡å®šåˆ™å®Œæˆè¯¥æ­¥å‰©ä½™æœªå®Œæˆä»»åŠ¡
	-a,   --add   : æ˜¯å¦åªè¿è¡ŒåŠ æµ‹çš„æ ·å“ï¼Œå¦‚æžœæŒ‡å®šåˆ™åªè¿è¡ŒåŠ æµ‹çš„æ ·å“ã€‚æ³¨æ„çš„æ˜¯ï¼Œ-aä¸å¯ä¸Ž-cåŒæ—¶ä½¿ç”¨ã€‚å¦‚æžœä½¿ç”¨-aï¼Œéœ€è¦å°†ä¹‹å‰çš„logæ–‡ä»¶åˆ é™¤å¹²å‡€ï¼Œå¦åˆ™ä¸ä¼šè¿è¡Œä»»åŠ¡ï¼›
	-quota, --quota : åˆ†æžç›®å½•çš„é…é¢ï¼Œæ˜¯ä¹‹å‰æ‰¾æ–‡æ˜Žç”³è¯·çš„å¤§å°ã€‚é»˜è®¤æ˜¯1000Gï¼Œè¯·æ ¹æ®å®žé™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚
è¯´æ˜Žï¼š
	Q: æ”¯çº¿ä»»åŠ¡æ–­äº†å’‹åŠžï¼Ÿ
	A: æ”¯çº¿ä»»åŠ¡æ–­äº†ï¼Œä¸»çº¿ä»»åŠ¡ä¼šç»§ç»­è¿è¡Œï¼Œè€Œæ•´ä¸ªæµç¨‹ä¸å—å½±å“ã€‚ä½†æ˜¯æŸ¥çœ‹show_processçš„æ—¶å€™ï¼Œå¯ä»¥çœ‹åˆ°breakçš„çŠ¶æ€ã€‚è€Œbreakçš„ç­‰çº§æ˜¯é«˜äºŽrunå’Œholdçš„ï¼Œå› æ­¤ï¼Œéœ€è¦è‡ªè¡Œåˆ¤å®šç¨‹åºæ˜¯å¦å®Œæˆã€‚

	Q: ä¸»çº¿ä»»åŠ¡æ–­äº†å’‹åŠžï¼Ÿ
	A: ä¸»çº¿æ–­äº†ï¼Œé‚£ä¹ˆå°±æ–­äº†ï¼Œéœ€è¦é‡æ–°æŠ•é€’ã€‚
	   å¦‚æžœä¸»çº¿ä»»åŠ¡æ–­äº†ï¼Œè€Œæ”¯çº¿ä»»åŠ¡æ²¡æœ‰å®Œæˆï¼Œé‚£ä¹ˆä¸»ç¨‹åºä¼šç­‰å€™æ”¯çº¿ä»»åŠ¡å®Œæˆæ‰ä¼šå®žçŽ°æœ€ç»ˆçš„é€€å‡ºï¼Œæ‰€ä»¥ä¼šå¯¼è‡´ç¨‹åºä¸€ç›´åœ¨è¿è¡Œçš„å‡è±¡ã€‚è¿™ä¸ªæ—¶å€™æœ‰ä¸¤ä¸ªå¤„ç†åŠžæ³•ï¼š
	   1. æŠŠæ‰€æœ‰è¿›ç¨‹éƒ½æ€æŽ‰ï¼Œç„¶åŽé‡æ–°æŠ•é€’
	   2. åªæ€æŽ‰ä¸»è¿›ç¨‹ï¼ˆpipeline.py)ï¼Œå¹¶ä¸”åœ¨log.txtä¸­äººä¸ºæ·»åŠ æ”¯çº¿ä»»åŠ¡çš„finishæ ‡è¯†ï¼ˆé˜²æ­¢å†æ¬¡è¿è¡Œpipeline.pyæ—¶é‡æ–°æŠ•é€’ï¼‰ï¼Œä¹‹åŽé‡æ–°è¿è¡Œè¯¥ä»»åŠ¡ã€‚
	Q:å¦‚ä½•è¯†åˆ«åŠ æµ‹æ ·å“ï¼Ÿ
	A:å½“æŸä¸€å—å‡ºçŽ°ä¸¤æ¬¡æˆ–è€…å¤šæ¬¡ï¼Œé‚£ä¹ˆæœ€åŽä¸€æ¬¡å‡ºçŽ°çš„å†…å®¹ä½œä¸ºåŠ æµ‹é¡¹

	Q:å¦‚ä½•ç›‘æŽ§é¡¹ç›®è¿è¡ŒçŠ¶æ€ï¼Ÿ
	A:è¿è¡Œ/annoroad/bioinfo/PMO/liutao/pipeline_generate/bin/current/show_process.pyä¼šæ˜¾ç¤ºé¡¹ç›®çš„çŠ¶æ€ã€‚é¡¹ç›®è¿è¡ŒçŠ¶æ€åˆ†ä¸ºrunning, break, plan, end å››ç§ã€‚å…¶ä¸­runningè¡¨ç¤ºæ­£åœ¨è¿è¡Œï¼Œbreakè¡¨ç¤ºä¸­æ–­ï¼Œplanè¡¨ç¤ºå‡†å¤‡è¿è¡Œï¼Œendè¡¨ç¤ºè¿è¡Œå®Œæˆ,holdè¡¨ç¤ºç£ç›˜ä¸å¤Ÿï¼Œä»»åŠ¡æŒ‚èµ·ã€‚

	Q: å‘çŽ°ä»»åŠ¡çŠ¶æ€æ˜¯breakï¼Œè¯¥å’‹åŠžï¼Ÿ
	A: å½“å‘çŽ°ä»»åŠ¡çŠ¶æ€æ˜¯breakçš„æ—¶å€™ï¼Œé¦–å…ˆéœ€è¦ç¡®å®šbreakæŽ‰çš„ä»»åŠ¡æ˜¯å¦æ˜¯ä¸»çº¿ä»»åŠ¡ã€‚
	   å¦‚æžœæ˜¯ä¸»çº¿ä»»åŠ¡ï¼Œå¦‚æžœä¸»ç¨‹åºè‡ªç„¶é€€å‡º(åœ¨topæˆ–è€…psçš„æ—¶å€™æ²¡æœ‰å‘çŽ°pipeline.pyï¼‰ï¼Œåˆ™å¯ä»¥é‡æ–°æŠ•é€’ä»»åŠ¡ï¼›
	                   å¦‚æžœæ²¡æœ‰è‡ªç„¶é€€å‡ºï¼ˆä¸»ç¨‹åºpipeline.pyè¿˜åœ¨è¿è¡Œï¼‰ï¼Œé‚£ä¹ˆå¯èƒ½æ˜¯æœ‰ä¹‹å‰çš„æ”¯çº¿ä»»åŠ¡æœªå®Œæˆï¼Œå¯ä»¥å‚ç…§Q2æ¥è¿›è¡Œæ“ä½œï¼›
	   å¦‚æžœæ˜¯æ”¯çº¿ä»»åŠ¡ï¼Œå¦‚æžœæŸ¥çœ‹log.txtå‘çŽ°ä¸»çº¿ä»»åŠ¡å…¨éƒ¨å®Œæˆæˆ–è€…æ­£å¸¸è¿è¡Œï¼Œå¦‚æžœæ—¶é—´å…è®¸ï¼Œå¯ä»¥ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®ŒæˆåŽå†æŠ•é€’ä»»åŠ¡ï¼›
	                                                                    å¦‚æžœåŠ æ€¥ï¼Œå¯ä»¥æŠŠè¯¥æ­¥å¯¹åº”çš„shæ–‡ä»¶ä¿®æ”¹åŽï¼Œæ‰‹åŠ¨æŠ•é€’è¯¥ä»»åŠ¡ï¼›
	                   å¦‚æžœä¸»çº¿ä»»åŠ¡ä¹Ÿæ–­æŽ‰äº†ï¼Œé‚£ä¹ˆä¿®æ”¹è„šæœ¬åŽï¼Œé‡æ–°æŠ•é€’æ‰€æœ‰ä»»åŠ¡ã€‚

	Q:ç›‘æŽ§é¡¹ç›®çš„è®°å½•æ–‡ä»¶åœ¨å“ªï¼Ÿ
	A:ç¨‹åºä¼šåœ¨æ‚¨çš„homeç›®å½•ä¸‹ï¼Œç”Ÿæˆä¸€ä¸ªè®°å½•æ–‡ä»¶ï¼Œè·¯å¾„ä¸º~/.mission/.pipeline.logï¼Œè®°å½•äº†æ¯ä¸ªé¡¹ç›®çš„åˆ†æžç›®å½•ã€‚å¦‚æžœä¸æƒ³æ˜¾ç¤ºæŸä¸ªé¡¹ç›®ï¼Œå¯ä»¥å¯¹ç›¸åº”çš„è¡Œè¿›è¡Œåˆ é™¤æˆ–è€…ç¼–è¾‘ã€‚

	Q:å¦‚æžœç¨‹åºæ–­äº†ï¼Œå’‹åŠžï¼Ÿ
	A:å¦‚æžœç¨‹åºç”±äºŽå„ç§å› ç´ ä¸­æ–­äº†ï¼Œä»”ç»†æ£€æŸ¥è„šæœ¬ï¼Œå¦‚æžœè„šæœ¬æ²¡é”™ï¼Œç¡®å®šåªæ˜¯ä¸­æ–­ï¼Œé‚£ä¹ˆé‡æ–°è¿è¡Œä¸€æ¬¡ä¹‹å‰çš„è„šæœ¬ï¼Œé»˜è®¤ä¼šæŠŠæ–­æŽ‰çš„æ¨¡å—å…¨éƒ¨é‡å¤´è¿è¡Œï¼›å¦‚æžœä¸æƒ³å°†è¯¥æ¨¡å—å†…å·²ç»å®Œæˆçš„æ ·å“é‡æ–°è¿è¡Œï¼Œå¯ä»¥åŠ ä¸Š-cå‚æ•°ï¼Œé‚£ä¹ˆä¼šåªè¿è¡Œæ²¡æœ‰è¿è¡ŒæˆåŠŸçš„æ ·å“ã€‚

	Q:å¦‚ä½•å‘çŽ°é…é¢ä¸å¤Ÿï¼Ÿ
	A:å¦‚æžœé…é¢ä¸å¤Ÿäº†ï¼Œä¼šæŠŠæ‰€æœ‰çš„ä»»åŠ¡æŒ‚èµ·ï¼Œä½¿ç”¨show_processæŸ¥çœ‹æ—¶ï¼Œä¼šå‘çŽ°HoldçŠ¶æ€ï¼›æˆ–è€…ä½¿ç”¨qstatçš„æ—¶å€™ï¼Œä¼šå‘çŽ°hqwï¼Œhrï¼Œhtç­‰ï¼Œæˆ–è€…æ²¡æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼ˆå› ä¸ºé…é¢ä¸å¤Ÿï¼Œç¨‹åºä¼šè‡ªåŠ¨ä¸æŠ•é€’ä»»åŠ¡ï¼‰

	Q: é…é¢ä¸å¤Ÿäº†ï¼Œå’‹åŠžï¼Ÿ
	A: ç¬¬ä¸€ï¼Œæ‰¾æ–‡æ˜Žä¿®æ”¹é…é¢ ï¼› ç¬¬äºŒï¼Œä¿®æ”¹ç›¸åº”çš„sh.*.logæ–‡ä»¶ï¼ŒåŠ å…¥ä¸€è¡ŒDISK_QUOTA	**G ;ä¹‹åŽï¼Œç¨‹åºä¼šè‡ªåŠ¨çš„releaseã€‚ä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºä¹‹å‰åœ¨ç¨‹åºé‡Œè®¾ç½®äº†è¾ƒå°çš„é…é¢ï¼Œæ‰€ä»¥ä¹‹åŽæ¯ä¸€æ­¥éƒ½ä¼šè¢«holdã€‚æ‰€ä»¥éœ€è¦ä¹‹åŽæ¯ä¸ªlogæ–‡ä»¶éƒ½åŠ ä¸Š DISK_QUOTA	**Gï¼Œæ¥æ¯æ¬¡è¿›è¡Œæ›´æ”¹ï¼›æˆ–è€…æ€æŽ‰é‡æ–°æ¥ã€‚ 
	   æˆ–è€…åˆ é™¤æ–‡ä»¶æ¥é‡Šæ”¾ç©ºé—´ï¼Œè¿™æ ·çš„è¯ï¼ŒåŽé¢å¯ä»¥ä¸ç”¨ä¿®æ”¹å°±å¯ä»¥è¿è¡Œã€‚

	Q: å¦‚ä½•æ€æŽ‰ç¨‹åºï¼Ÿ
	A: 1. æ€æŽ‰æ‰€æœ‰çš„å­è¿›ç¨‹ å®ˆæŠ¤è¿›ç¨‹qsub_sge.plï¼Œå¦åˆ™çš„æ€æŽ‰çš„ä»»åŠ¡ä¼šé‡æ–°æŠ•é€’ï¼›
	   2. æ€æŽ‰æ‰€æœ‰çš„ä»»åŠ¡ qdelæŽ‰

	Q: å¦‚ä½•ç²¾å‡†çš„æ€æŽ‰å®ˆæŠ¤è¿›ç¨‹ï¼Ÿ
	A: 1. åœ¨é‡æ–°æŠ•é€’ä¹‹å‰ï¼Œä½¿ç”¨ps -f -u name |cat ç„¶åŽä»”ç»†çš„åˆ¤åˆ«ï¼ŒèŽ·å¾—è¿›ç¨‹ID
	   2. æŸ¥çœ‹shellåŽé¢çš„æ•°å­—ï¼Œåœ¨sh å’Œlogç›´æŽ¥çš„æ•°å­—ï¼Œæ˜¯è¿›ç¨‹IDï¼Œä½¿ç”¨kill -9å¯ä»¥æ€æŽ‰
æ›´æ–°è¯´æ˜Žï¼š
	2015-8-17
	1.ä¹‹å‰ä¸€ä¸ªtargetæ–­æŽ‰åŽï¼Œéœ€è¦å¯¹è¿™ä¸ªtargeté‡Œçš„æ‰€æœ‰ä»»åŠ¡é‡æ–°æŠ•é€’ï¼›ç›®å‰åŠ ä¸Šäº†-c å‚æ•°ï¼Œå¯ä»¥é€‰æ‹©è·³è¿‡å·²è¿è¡Œå®Œæ¯•çš„ä»»åŠ¡
	2015-9-1
	1. åŠ å…¥quotaå‚æ•°ï¼Œå¦‚æžœç›®å½•é…é¢ä¸å¤Ÿï¼Œä¼šè‡ªåŠ¨æŒ‚èµ·ä»»åŠ¡ï¼›
	2. åŠ å…¥sh.*.logæ–‡ä»¶ä¸­çš„èŠ‚ç‚¹çš„è®°å½•
	3. åŠ å…¥äº†maxcycleï¼Œå¯ä»¥åœ¨pipeline.pyå¯¹maxcycleä¸­è¿›è¡Œä¿®æ”¹
	4. ä¿®æ”¹æ”¯çº¿ä»»åŠ¡æ–­æŽ‰ï¼Œä¸å½±å“ä¸»çº¿ä»»åŠ¡æ•´ä½“è¿è¡Œã€‚
	2015-10-8
	1. æ·»åŠ äº†æ¯ä¸ªä»»åŠ¡æŠ•é€’æ—¶çš„çº¿ç¨‹æ•°ï¼Œåœ¨æœ€åˆçš„configæ–‡ä»¶ä¸­ä½¿ç”¨ThreadæŽ§åˆ¶ï¼Œé»˜è®¤ä¸º1.
	2016-03-26
	1. åœ¨shellä¸‹é¢çš„logæ–‡ä»¶ä¸­ï¼Œæ·»åŠ äº†ä½¿ç”¨ç¨‹åºç‰ˆæœ¬çš„è®°å½•ï¼Œæ–¹ä¾¿ä»¥åŽå‡çº§æ—¶ï¼Œå¯ä»¥è¿›è¡ŒæŸ¥æ‰¾ã€‚
'''
#! /usr/bin/env python3
# -*- coding: utf-8 -*-  
import argparse
import sys
import os
import re
bindir = os.path.abspath(os.path.dirname(__file__))
sys.path.append('{0}/lib'.format(bindir))
import parseConfig
import JobGuard

__author__='Liu Tao'
__mail__= 'taoliu@annoroad.com'

pat1=re.compile('^\s+$')

def main():
	parser=argparse.ArgumentParser(description=__doc__,
			formatter_class=argparse.RawDescriptionHelpFormatter,
			epilog='author:\t{0}\nmail:\t{1}'.format(__author__,__mail__))
	parser.add_argument('-i','--input',help='input file',dest='input',type=open,required=True)
	parser.add_argument('-b','--bin',help='bin dir',dest='bin',default=os.path.dirname(bindir))
	parser.add_argument('-t','--thread',help='thread number ',dest='thread',type=int)
	parser.add_argument('-q','--queue',help='computer queue name ',dest='queue')
	parser.add_argument('-P','--P',help='Project in qsub ',dest='qsub_P' , default='none')
	parser.add_argument('-o','--outdir',help='output file',dest='outdir',required=True)
	parser.add_argument('-indir','--indir',help='indir data file',dest='indir',default='')
	parser.add_argument('-name','--name',help='project name',dest='name',required=True)
	parser.add_argument('-j','--jobid',help='job id prefix',dest='jobid',default='')
	parser.add_argument('-r','--run',help='run script file',dest='run',action='store_true')
	parser.add_argument('-nc','--noncontinue',help='continue unfinish job in each shell',dest='noncontinues',action='store_true')
	#parser.add_argument('-n','--nohup',help='qsub or nohup mission',dest='nohup',action='store_true')
	parser.add_argument('-quota','--quota',help='disk quota ',dest='quota',default = '1000G')
	parser.add_argument('-a','--add',help='add sequencing sample process, True -- only run added sequence sample ,False* -- run all samples',dest='add',action='store_true')
	args=parser.parse_args()

	OUTDIR = parseConfig.getab(args.outdir)
	INDIR = parseConfig.getab(args.indir)
	BIN=os.path.realpath(args.bin)
	LOGFILE = '{0}/log.txt'.format(OUTDIR)
	
	job_not_continue = '  '
	if args.noncontinues : job_not_continue = '  -nc  '

	if args.jobid == '' : args.jobid = args.name
	config ,para, db , orders  = parseConfig.ReadConfig(args.input)
	shell_dir = '{0}/shell/'.format(OUTDIR)
	parseConfig.makedir(shell_dir)
	logfile = '{0}/log.txt'.format(shell_dir)
	finish_obj = JobGuard.ReadLog(logfile)
	log = open(logfile,'a')
	log.write('#pipeline version : {0}\n'.format(BIN))
	guard_script = '{0}/guard.py'.format(shell_dir)
	job_list = {}
	all_job_list = {}

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/1_0_MarkerAnno.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} sample={sample[0]} infile={sample[1]} outdir={sample[2]} relation_file={para[Para_relation_file]} anno_file={para[Para_anno_file]} Anno'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}MarkerAnno -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}MarkerAnno -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}MarkerAnno -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}MarkerAnno -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( [] ) == 0 : 
			a_thread = JobGuard.MyThread('1_0_MarkerAnno' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('1_0_MarkerAnno' , log , a_cmd, False , [ all_job_list[ i ] for i in [] ])
		all_job_list[ 'MarkerAnno' ] = a_thread
		if not int(1) in job_list: job_list[int(1)] = []
		job_list[int(1)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/2_0_UpGO.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} outdir={sample[2]}/up/ up_or_down=Up infile={sample[2]}/$(sample).csv GetList\nmake -f {BIN}/bin/anno.mk log_file={LOGFILE} gene_list={sample[2]}/up/Up.gene.xls go_dir={sample[2]}/up/GO sample={sample[0]} go={para[Para_go_list]} GO'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpGO -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpGO -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpGO -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpGO -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( ['MarkerAnno'] ) == 0 : 
			a_thread = JobGuard.MyThread('2_0_UpGO' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('2_0_UpGO' , log , a_cmd, False , [ all_job_list[ i ] for i in ['MarkerAnno'] ])
		all_job_list[ 'UpGO' ] = a_thread
		if not int(2) in job_list: job_list[int(2)] = []
		job_list[int(2)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/2_1_DownGO.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} outdir={sample[2]}/down/ up_or_down=Down infile={sample[2]}/$(sample).csv GetList\nmake -f {BIN}/bin/anno.mk log_file={LOGFILE} gene_list={sample[2]}/down/Down.gene.xls go_dir={sample[2]}/down/GO sample={sample[0]} go={para[Para_go_list]} GO'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownGO -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownGO -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownGO -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownGO -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( ['MarkerAnno'] ) == 0 : 
			a_thread = JobGuard.MyThread('2_1_DownGO' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('2_1_DownGO' , log , a_cmd, False , [ all_job_list[ i ] for i in ['MarkerAnno'] ])
		all_job_list[ 'DownGO' ] = a_thread
		if not int(2) in job_list: job_list[int(2)] = []
		job_list[int(2)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/2_2_AllGO.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} gene_list={sample[2]}/$(sample).csv go_dir={sample[2]}/all/GO sample={sample[0]} go={para[Para_go_list]} GO'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllGO -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllGO -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllGO -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllGO -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( ['MarkerAnno'] ) == 0 : 
			a_thread = JobGuard.MyThread('2_2_AllGO' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('2_2_AllGO' , log , a_cmd, False , [ all_job_list[ i ] for i in ['MarkerAnno'] ])
		all_job_list[ 'AllGO' ] = a_thread
		if not int(2) in job_list: job_list[int(2)] = []
		job_list[int(2)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/2_3_UpKEGG.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} outdir={sample[2]}/up/ up_or_down=Up infile={sample[2]}/$(sample).csv GetList\nmake -f {BIN}/bin/anno.mk log_file={LOGFILE} gene_list={sample[2]}/up/Up.gene.xls go_dir={sample[2]}/up/GO sample={sample[0]} kegg={para[Para_kegg_list]} category=animal KEGG'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpKEGG -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpKEGG -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpKEGG -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}UpKEGG -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( ['MarkerAnno'] ) == 0 : 
			a_thread = JobGuard.MyThread('2_3_UpKEGG' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('2_3_UpKEGG' , log , a_cmd, False , [ all_job_list[ i ] for i in ['MarkerAnno'] ])
		all_job_list[ 'UpKEGG' ] = a_thread
		if not int(2) in job_list: job_list[int(2)] = []
		job_list[int(2)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/2_4_DownKEGG.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} outdir={sample[2]}/down/ up_or_down=Down infile={sample[2]}/$(sample).csv GetList\nmake -f {BIN}/bin/anno.mk log_file={LOGFILE} gene_list={sample[2]}/down/Down.gene.xls go_dir={sample[2]}/down/GO sample={sample[0]} kegg={para[Para_kegg_list]} category=animal KEGG'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 2 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownKEGG -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownKEGG -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownKEGG -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 2 --maxcycle 5 --quota {6}  --jobprefix {3}DownKEGG -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( ['MarkerAnno'] ) == 0 : 
			a_thread = JobGuard.MyThread('2_4_DownKEGG' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('2_4_DownKEGG' , log , a_cmd, False , [ all_job_list[ i ] for i in ['MarkerAnno'] ])
		all_job_list[ 'DownKEGG' ] = a_thread
		if not int(2) in job_list: job_list[int(2)] = []
		job_list[int(2)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	run_sample = config['sample']
	pre_job_count = 0 
	if args.add :
		run_sample , pre_job_count = parseConfig.chooseSamples(run_sample, orders['sample'])
	#print(run_sample)
	if len(run_sample) > 0 :
		shsh = '{0}/2_5_AllKEGG.sh'.format(shell_dir)
		with open(shsh, 'w') as f_out:
			cmds = []
			cpu = parseConfig.cpu(args.thread , len(run_sample), 'N' )
			queue = parseConfig.queue(args.queue , 'sci.q')
			for sample in sorted(run_sample):
				cmds.append('make -f {BIN}/bin/anno.mk log_file={LOGFILE} gene_list={sample[2]}/$(sample).csv go_dir={sample[2]}/all/GO sample={sample[0]} kegg={para[Para_kegg_list]} category=animal KEGG'.format(para=para , sample =sample ,OUTDIR=OUTDIR, BIN=BIN,db=db,LOGFILE=LOGFILE, INDIR=INDIR) )
			f_out.write("\n".join(sorted(set(cmds))) + '\n')
		if not False :
			if "" == '':
				if "" == '':
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 {0}'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 --mount / --sif   {0}'.format(shsh , bindir, cpu)
			else:
				if "" == '':
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 {0}"'.format(shsh , bindir, cpu)
				else :
					a_cmd = 'ssh  2> /dev/null "perl {1}/src/slurm/multi-process.pl -cpu {2} --lines 1 --mount / --sif   {0}"'.format(shsh , bindir, cpu)
		else:
			if "" == '':
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllKEGG -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllKEGG -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
			else :
				if "" == '':
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllKEGG -P {8}  {5} --queue {4} {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
				else :
					a_cmd = '{1}/src/slurm/slurm_sge --resource "p=1,vf=5G,h=" --maxjob {2} --lines 1 --maxcycle 5 --quota {6}  --jobprefix {3}AllKEGG -P {8}  {5} --queue {4}  -mount / -s  {0} --jobidstart {7} '.format(shsh ,bindir, cpu, args.jobid , queue , job_not_continue , args.quota , pre_job_count , args.qsub_P)
		if len( ['MarkerAnno'] ) == 0 : 
			a_thread = JobGuard.MyThread('2_5_AllKEGG' , log , a_cmd, False)
		else : 
			a_thread = JobGuard.MyThread('2_5_AllKEGG' , log , a_cmd, False , [ all_job_list[ i ] for i in ['MarkerAnno'] ])
		all_job_list[ 'AllKEGG' ] = a_thread
		if not int(2) in job_list: job_list[int(2)] = []
		job_list[int(2)].append(a_thread)
	else:
		print("{0} is empty".format("config['sample']"))

	home_dir = os.environ['HOME']
	parseConfig.makedir('{0}/.mission'.format(home_dir))
	if not os.path.isfile('{0}/.mission/.pipeline.log'.format(home_dir)):
		os.system('touch {0}/.mission/.pipeline.log'.format(home_dir))
	
	tag = 0 
	with open('{0}/.mission/.pipeline.log'.format(home_dir),'r') as super_log:
		for line in super_log:
			if line.startswith('#') or re.search(pat1,line):continue
			tmp = line.rstrip().split()
			if tmp[0] == args.name:
				tag = 1
				if tmp[1] == os.path.abspath(args.outdir):
					tag = 2
	
	if tag == 0 : 
		with open('{0}/.mission/.pipeline.log'.format(home_dir),'a') as super_log:
			super_log.write('{0}\t{1}\n'.format(args.name , os.path.abspath(args.outdir)))
	elif tag == 2 :
		print("[1;31;40m" + "Warings: {0} was existed already in your log file, please check it".format(args.name) + "[0m")
	elif tag == 1 :
		print("[1;31;40m" + "Warings: {0} was existed already in your log file,  and have different analysis directory , we should add this new dir at the end of log file ,please check it".format(args.name) + "[0m")
		with open('{0}/.mission/.pipeline.log'.format(home_dir),'a') as super_log:
			super_log.write('{0}\t{1}\n'.format(args.name , os.path.abspath(args.outdir)))
	
	print(JobGuard.dump_jobs(job_list))
	job_list = JobGuard.RemoveFinish(job_list,finish_obj)
	if args.run == True:
		JobGuard.run(job_list , log)
	log.close()

if __name__ == '__main__':
	main()
